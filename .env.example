# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_ENV=development

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Google Gemini Configuration (Alternative to OpenAI)
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-pro

# Vector Database - Pinecone
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=plc-logic-patterns

# Vector Database - ChromaDB (Local Alternative)
CHROMADB_HOST=localhost
CHROMADB_PORT=8001
CHROMADB_COLLECTION=plc_embeddings

# LLM Provider (openai or gemini) - Gemini is FREE!
LLM_PROVIDER=gemini

# Vector DB Provider (pinecone or chromadb) - ChromaDB is FREE & local!
VECTOR_DB_PROVIDER=chromadb

# CORS Settings
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# File Upload
MAX_UPLOAD_SIZE=10485760  # 10MB in bytes

# LLM Generation Settings
MAX_GENERATION_TOKENS=32000  # Maximum tokens for L5X generation (Gemini Flash supports up to 65K)
GENERATION_TEMPERATURE=0.1   # Low temperature for consistent output

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
